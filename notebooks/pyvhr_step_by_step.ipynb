{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyvhr_step_by_step.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6OPv9EZze86"
      },
      "source": [
        "#PYVHR STEP BY STEP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmGYQh29rs6F"
      },
      "source": [
        "Import everything we will need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWXk2mwaeuJ-"
      },
      "source": [
        "from pyVHR.extraction.sig_processing import *\n",
        "from pyVHR.BVP.BVP import *\n",
        "from pyVHR.BPM.BPM import *\n",
        "from pyVHR.BVP.methods import *\n",
        "from pyVHR.BVP.filters import *\n",
        "from pyVHR.plot.visualize import *\n",
        "\n",
        "# PLOTTING\n",
        "# 'colab' or 'notebook'\n",
        "VisualizeParams.renderer = 'colab'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG78iDwzsGwn"
      },
      "source": [
        "First create a dataset object by using the datasetFactory. LGI_PPGI is inside the pyVHR package, but you can use also custom dataset class!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHKQ6bT-BPuH"
      },
      "source": [
        "from pyVHR.datasets.dataset import datasetFactory\n",
        "from pyVHR.utils.errors import *\n",
        "\n",
        "dataset_name = 'pure'\n",
        "video_DIR = '/var/datasets/VHR1/' \n",
        "BVP_DIR = '/var/datasets/VHR1/'\n",
        "\n",
        "dataset = datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)\n",
        "allvideo = dataset.videoFilenames\n",
        "\n",
        "# print the list of video with the progressive index (idx)\n",
        "for v in range(len(allvideo)):\n",
        "  print(v, allvideo[v])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEL85ZqnsayK"
      },
      "source": [
        "The window size *wsize* will be used for extracting both the ground truth BPM, and estimated BPM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF5qS-lZwUZo"
      },
      "source": [
        "wsize = 8 #seconds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LQSjuNjNkL5"
      },
      "source": [
        "Ground Truth extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPX8RrgA5bva"
      },
      "source": [
        "video_idx = 19\n",
        "fname = dataset.getSigFilename(video_idx)\n",
        "sigGT = dataset.readSigfile(fname)\n",
        "test_bvp = sigGT.data\n",
        "bpmGT, timesGT = sigGT.getBPM(wsize)\n",
        "videoFileName = dataset.getVideoFilename(video_idx)\n",
        "#videoFileName = \"/home/devel/mortara_realtime/video/me.mp4\"\n",
        "print(videoFileName)\n",
        "fps = get_fps(videoFileName)\n",
        "print(fps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaVBUDHET1IC"
      },
      "source": [
        "#display_video(videoFileName)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrstGwlls1N3"
      },
      "source": [
        "**pyVHR** is structured in a simple way. \n",
        "\n",
        "There are 3 main steps for obtaining the estimated BPM:\n",
        "\n",
        "\n",
        "1.   Signal extraction\n",
        "2.   BVP extraction\n",
        "3.   BPM extraction\n",
        "\n",
        "The first step is carried out by the *SignalProcessing* class. This class can be accelerated by using a CUDA device.\n",
        "\n",
        "*SignalProcessing* compute the signal in two ways:\n",
        "\n",
        "\n",
        "*   Holistic mean: the whole skin is considered as a single estimator\n",
        "*   Patches mean: facial regions, each one with a center called landmark. Each region is an estimator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "627hefyyeXDT"
      },
      "source": [
        "sig_extractor = SignalProcessing()\n",
        "sig_extractor.display_cuda_device()\n",
        "sig_extractor.choose_cuda_device(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW6ph-b6IAST"
      },
      "source": [
        "The SignalProcessing class can use different skin extractors:\n",
        "\n",
        "\n",
        "*   Convex Hull skin extractor\n",
        "*   Face Parsing skin extractor\n",
        "\n",
        "Both work with CPU and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XYUpdNQIQPa"
      },
      "source": [
        "sig_extractor.set_skin_extractor(SkinExtractionFaceParsing('GPU'))\n",
        "sig_extractor.set_skin_extractor(SkinExtractionConvexHull('GPU'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co7hIvT_IqzW"
      },
      "source": [
        "We can choose to process a specific number of frames of the video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXt1POLtfhW3"
      },
      "source": [
        "# To precess the whole video pass 0\n",
        "sig_extractor.set_total_frames(0*fps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF_pZJYheiVL"
      },
      "source": [
        "Both signal extraction and skin extraction have a color-threshold filter for removing unwanted RGB colors.\n",
        "We can set the RGB threshold interval using theese classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SmUo73we_Ds"
      },
      "source": [
        "SkinProcessingParams.RGB_LOW_TH = 2\n",
        "SkinProcessingParams.RGB_HIGH_TH = 254\n",
        "\n",
        "SignalProcessingParams.RGB_LOW_TH = 2\n",
        "SignalProcessingParams.RGB_HIGH_TH = 254"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_B005iFtwxQ"
      },
      "source": [
        "We can save intermediate results by calling the \n",
        "\"*set_visualize_skin_and_landmarks*\" method. \n",
        "\n",
        "We can retrieve any intermediate result by calling the methods:\n",
        "\n",
        "\n",
        "*   get_visualize_skin\n",
        "*   get_visualize_patches\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrpqmbikhG_l"
      },
      "source": [
        "sig_extractor.set_visualize_skin_and_landmarks(\n",
        "    visualize_skin=False, visualize_landmarks=False, visualize_landmarks_number=False, visualize_patch=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrqPGezuhIbA"
      },
      "source": [
        "sig_extractor.set_visualize_skin_and_landmarks(\n",
        "    visualize_skin=True, visualize_landmarks=True, visualize_landmarks_number=True, visualize_patch=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBR3DV6augjO"
      },
      "source": [
        "The SignalProcessing class allows you to extract the signal using customizable facial regions; the center of a region is called landmark. There are 468 landmarks, and we can use any combination of these.\n",
        "\n",
        "This script is very useful for viewing all the possible facial landmarks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKfR_FbTZFlf"
      },
      "source": [
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.forehead_center)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.forehead_left)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.forehoead_right)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.eye_left)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.eye_right)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.nose)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.mounth_down)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.mounth_up)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.chin)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.cheek_left_bottom)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.cheek_left_top)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.cheek_right_bottom)\n",
        "# visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", MagicLandmarks.cheek_right_top)\n",
        "visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", [_ for _ in range(468)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlPd-8QXsDzl"
      },
      "source": [
        "#filter_landmarks = [i for i in range(1,468)]\n",
        "filter_landmarks = MagicLandmarks.cheek_left_top +\\\n",
        "                   MagicLandmarks.cheek_right_top +\\\n",
        "                   MagicLandmarks.forehead_center +\\\n",
        "                   MagicLandmarks.forehoead_right +\\\n",
        "                   MagicLandmarks.forehead_left +\\\n",
        "                   MagicLandmarks.mounth_up \n",
        "filter_landmarks = [8, 9, 266, 10, 142, 151, 279, 280, 411, 285, 417, 290, 36, 423, 168, 425, 426, 427, 297, 299, 298, 48, 50, 436, 437, 55, 440, 187, 67, 293, 69, 420, 455, 329, 330, 203, 205, 206, 333, 336, 337, 338, 207, 216,122,4,197,195,193,5,126, 346, 347, 351, 101, 107, 108, 109, 371, 118]\n",
        "filter_landmarks = list(dict.fromkeys(filter_landmarks))\n",
        "print(len(filter_landmarks))\n",
        "visualize_landmarks_list(\"/home/devel/pyVHR_pack/example.jpg\", filter_landmarks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuRxs_0_w6To"
      },
      "source": [
        "\n",
        "Once we have chosen the list of landmarks, we can pass it to a SignalProcessing object by calling the following method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8pmLyTKkhCo"
      },
      "source": [
        "sig_extractor.set_landmarks(filter_landmarks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXFwg6twximv"
      },
      "source": [
        "Here are some examples of signal extraction.\n",
        "\n",
        "\n",
        "1.   Holistic mean\n",
        "2.   Rectangular Patches mean\n",
        "3.   Square Patches mean\n",
        "\n",
        "For Rectangular Patches we can choose the xy_dimension of each region.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXcR6pc49HL_"
      },
      "source": [
        "# HOLISTIC EXTRACTION\n",
        "hol_sig = sig_extractor.extract_holistic(videoFileName,1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jmxPPmpW6gg"
      },
      "source": [
        "hol_sig.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxzLGh5rfYPC"
      },
      "source": [
        "# SQUARE EXTRACTION\n",
        "sig_extractor.set_square_patches_side(24.0)\n",
        "sig = sig_extractor.extract_patches(videoFileName, 1.0,\"squares\", \"mean\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWTcbyAyQPcY"
      },
      "source": [
        "sig.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF0MhV75ft5-"
      },
      "source": [
        "# RECTS EXTRACTION\n",
        "# rects_list = MagicLandmarks.cheek_left_top + MagicLandmarks.cheek_right_top\n",
        "# rects_sizes = []\n",
        "# for _ in rects_list:\n",
        "#    rects_sizes.append([30, 25])\n",
        "# sig_extractor.set_landmarks(rects_list)\n",
        "# sig_extractor.set_rect_patches_sides(\n",
        "#     np.array(rects_sizes, dtype=np.float32))\n",
        "# sig = sig_extractor.extract_patches(videoFileName, 1.0,\"rects\", \"mean\")\n",
        "# print(sig.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOT4EVvh_H_u"
      },
      "source": [
        "*SignalProcessing* class offers others usefull methods:\n",
        "\n",
        "\n",
        "*   extract_raw_holistic: returns an np.ndarray with shape (num_frames, 1, N x M x rgb_channels), where NxM is the aspect ratio of the video. This method extract the whole skin in each frame and set to RGB (0,0,0) the non-skin pixels.\n",
        "\n",
        "You can use Raw signal with the SSR method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_GupyyTBYpN"
      },
      "source": [
        "## RAW HOLISTIC and SSR method\n",
        "# raw_sig = sig_extractor.extract_raw_holistic(videoFileName,1.0)\n",
        "# print(raw_sig.shape)\n",
        "# windowed_raw_sig, raw_times = raw_windowing(raw_sig, wsize, 1, fps)\n",
        "# ssr_bvps = RGB_sig_to_BVP(windowed_raw_sig, fps, device_type='cpu', method=cpu_SSR, params={'fps':fps})\n",
        "# ssr_bpm = BVP_to_BPM(ssr_bvps, fps)\n",
        "# RMSE, MAE, MAX, PCC = getErrors(np.expand_dims(ssr_bpm, axis=0), bpmGT, raw_times, timesGT)\n",
        "# printErrors(RMSE, MAE, MAX, PCC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgKFP-miMKVZ"
      },
      "source": [
        "Let's plot extracted skin and patches!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE04zo6Xf2xl"
      },
      "source": [
        "visualize_skin_coll = sig_extractor.get_visualize_skin()\n",
        "visualize_patches_coll = sig_extractor.get_visualize_patches()\n",
        "print(len(visualize_skin_coll))\n",
        "print(len(visualize_patches_coll))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0pxgcm4ikm4"
      },
      "source": [
        "interactive_image_plot(visualize_skin_coll,.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6SxcW_bi-Sf"
      },
      "source": [
        "interactive_image_plot(visualize_patches_coll,0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fnzk_QEyH9L"
      },
      "source": [
        "Now we are ready to pass to the next step, but first we have to transform the whole signal in \n",
        "a windowed signal. A window has shape (num_estimators, rgb_channels, num_frames)\n",
        "\n",
        "Each window will become a single BPM estimate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYi_G8rzgfHB"
      },
      "source": [
        "# [usage] sig_windowing(sig, wsize, stride, fps)\n",
        "windowed_sig, timesES = sig_windowing(sig, wsize, 1, fps)\n",
        "print(len(windowed_sig))\n",
        "print(windowed_sig[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPXLgInXb2tl"
      },
      "source": [
        "visualize_windowed_sig(windowed_sig, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z_tKTqNkPaA"
      },
      "source": [
        "Pre Filterings\n",
        "\n",
        "\n",
        "*   \"rgb_filter_ths\": color threshold filter that filters out signals that, in at least one frame of the window, are outside the rgb colors interval [(LOW, LOW, LOW), (HIGH, HIGH, HIGH)]; where LOW is the dictionary parameter RGB_LOW_TH, and HIGH is RGB_HIGH_TH. We suggest to always use this filter before applying a BVP method.\n",
        "*   \"detrend\": apply detrend to the signal\n",
        "*   \"zscore\": apply z-score to the signal\n",
        "*   \"BPfilter\": apply Butterworth filter to the signal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E90CXeY2kPH8"
      },
      "source": [
        "# -- color threshold filtering\n",
        "filtered_windowed_sig = apply_filter(\n",
        "    windowed_sig, rgb_filter_th, params={'RGB_LOW_TH': 2, 'RGB_HIGH_TH': 254})\n",
        "print(filtered_windowed_sig[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX7gVjxrQxt9"
      },
      "source": [
        "filtered_windowed_sig = apply_filter(filtered_windowed_sig,BPfilter, params={'order':6,'minHz':0.65,'maxHz':4.0,'fps':fps})\n",
        "#filtered_windowed_sig = apply_filter(filtered_windowed_sig, detrend)\n",
        "#filtered_windowed_sig = apply_filter(filtered_windowed_sig, zscore)\n",
        "#filtered_windowed_sig = apply_filter(filtered_windowed_sig, zeromean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t1rI_MwsI_2"
      },
      "source": [
        "visualize_windowed_sig(filtered_windowed_sig,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxYmAQqezsG4"
      },
      "source": [
        "The second step is the BVP extraction.\n",
        "\n",
        "We only need to call the function \"*RGB_sig_to_BVP*\" and pass the following parameters:\n",
        "\n",
        "\n",
        "*   windowed signal\n",
        "*   fps\n",
        "*   method_type: 'cuda', 'cpu', 'torch'\n",
        "*   method: method function that supports method_type device\n",
        "*   params: dictionary of parameters needed by the method; default is {}.\n",
        "\n",
        "pyVHR contains many methods, but you can also use a custom method. Remember that it must accept a numpy.ndarray with shape (num_estimators, channels, num_frames) and return a numpy.ndarray with shape (num_estimators, num_frames)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sySCrAinghKt"
      },
      "source": [
        "bvps = RGB_sig_to_BVP(filtered_windowed_sig, fps, device_type='cuda', method=cupy_CHROM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OvQ8Au_1eLL"
      },
      "source": [
        "*bvps* is a list of length num_windows of numpy.ndarray with shape (num_estimators,num_frames)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_lZaw95mBtA"
      },
      "source": [
        "print(len(bvps))\n",
        "print(bvps[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2abphyGZjbA"
      },
      "source": [
        "Post Filtering\n",
        "\n",
        "We can apply all the filters showed before also to the *BVP*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovv6a1hTZlfr"
      },
      "source": [
        "bvps = apply_filter(bvps, BPfilter, params={'order':6,'minHz':0.65,'maxHz':4.0,'fps':fps})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCFL1QM1lnV4"
      },
      "source": [
        "visualize_BVPs(bvps, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kGmDLaA1BxR"
      },
      "source": [
        "Finally we need to extract the BPM. This function process all the windows and all the estimators, and returns a list of length num_windows of numpy.ndarray with shape (num_estimators, ).\n",
        "\n",
        "There is also a CUDA version of this function!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT5Q0v7qgjrh"
      },
      "source": [
        "bpmES = BVP_to_BPM(bvps, fps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFOUYLiIi-II"
      },
      "source": [
        "bpmES = BVP_to_BPM_cuda(bvps, fps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VooNsQqP2BXu"
      },
      "source": [
        "At this point we can have many BPM estimates for each time window. \n",
        "\n",
        "The function below compute for each window the median of the numpy.ndarray (num_estimators, )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLDlS0P1gl8H"
      },
      "source": [
        "median_bpmES = multi_est_BPM_median(bpmES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjmpPAl5mVLk"
      },
      "source": [
        "visualize_multi_est_BPM_vs_BPMs_list([bpmES,timesES], [[median_bpmES,timesES,\"medianES\"],[bpmGT,timesGT,\"GT\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWH48XrPLRMZ"
      },
      "source": [
        "Here the same steps, but for the holistic case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW73JVVFi1QS"
      },
      "source": [
        "# HOLISTIC analysis\n",
        "windowed_hol_sig, hol_timesES = sig_windowing(hol_sig, wsize, 1, fps)\n",
        "#windowed_hol_sig = apply_filter(windowed_hol_sig, detrend, params={})\n",
        "hol_bvps = RGB_sig_to_BVP(windowed_hol_sig, fps, device_type='cuda', method=cupy_CHROM)\n",
        "hol_bvps = apply_filter(hol_bvps, BPfilter, params={'minHz':0.65, 'maxHz':4.0, 'fps':fps, 'order':6})\n",
        "hol_bpmES = BVP_to_BPM(hol_bvps, fps)\n",
        "RMSE, MAE, MAX, PCC = getErrors(np.expand_dims(hol_bpmES, axis=0), bpmGT, hol_timesES, timesGT)\n",
        "printErrors(RMSE, MAE, MAX, PCC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypg681Pqjaps"
      },
      "source": [
        "This function plot a list of couple [BPMs, times, tag_Name]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoxwlY2ajaTP"
      },
      "source": [
        "#visualize_BPMs([[median_bpmES, timesES, \"medianES\"], [hol_bpmES, hol_timesES, \"holistic\"]])\n",
        "#visualize_BPMs([[median_bpmES, timesES, \"medianES\"], [bpmGT, timesGT, \"GT\"]])\n",
        "visualize_BPMs([[median_bpmES, timesES, \"medianES\"], [hol_bpmES, hol_timesES, \"holistic\"], [bpmGT, timesGT, \"GT\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSg5KALx2xpH"
      },
      "source": [
        "We are done!\n",
        "\n",
        "Let's plot errors!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU1Hg6E9gngX"
      },
      "source": [
        "from pyVHR.utils.errors import getErrors, printErrors, displayErrors\n",
        "RMSE, MAE, MAX, PCC = getErrors(np.expand_dims(median_bpmES, axis=0), bpmGT, timesES, timesGT)\n",
        "printErrors(RMSE, MAE, MAX, PCC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPwGa0aOhSLU"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "displayErrors(np.expand_dims(median_bpmES, axis=0), bpmGT, timesES, timesGT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3QZ2SUbGceA"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "displayErrors(np.expand_dims(hol_bpmES, axis=0), bpmGT, hol_timesES, timesGT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lGBunauy4qM"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd0e4EiDPpwN"
      },
      "source": [
        "Here some usefull plotting functions for PSD and Spectrum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG864HmTaDtk"
      },
      "source": [
        "visualize_BVPs_PSD(bvps, 0, fps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdjYl0J5dYIF"
      },
      "source": [
        "#display bvp spectr\n",
        "configure_plotly_browser_state()\n",
        "from pyVHR.BPM.BPM import BVPsignal\n",
        "obj = BVPsignal(bvps[0][0], fps)\n",
        "obj.spectrogram(winsize=wsize)\n",
        "obj.displaySpectrum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7VNuCzr7DWj"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# SNR ranking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWH1dmz37_IC"
      },
      "source": [
        "def compute_ranking(snr_peaks,bvp, perc):\n",
        "  ranking = []\n",
        "  i = 0\n",
        "  bvps_t = []\n",
        "  for window in snr_peaks:\n",
        "    temp = []\n",
        "    for est in window:\n",
        "      ratio = est[-1] / (est[-2] + 0.00000001)\n",
        "      temp.append(ratio)\n",
        "    ranking.append(temp)\n",
        "    top_half = np.argsort(ranking[i])[::-1]\n",
        "    top_half = top_half[:int(len(top_half)*perc)]\n",
        "    bvps_t.append( bvp[i][top_half] )\n",
        "    i+=1\n",
        "  return bvps_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWSMY4Ro_wOC"
      },
      "source": [
        "# bvps_pos = RGB_sig_to_BVP(filtered_windowed_sig, fps, device_type='cuda', method=cupy_POS, params={'fps':'adaptive'})\n",
        "# bvps_pca = RGB_sig_to_BVP(filtered_windowed_sig, fps, device_type='cpu', method=cpu_PCA, params={'component':'second_comp'})\n",
        "\n",
        "# snr_peaks = BVP_SNR(bvps,fps)\n",
        "# snr_peaks_pos = BVP_SNR(bvps_pos,fps)\n",
        "# snr_peaks_pca = BVP_SNR(bvps_pca,fps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BVNRKW5AJAi"
      },
      "source": [
        "# bvps_top = compute_ranking(snr_peaks,bvps, 0.30)\n",
        "# bvps_top_pos = compute_ranking(snr_peaks_pos,bvps_pos, 0.30)\n",
        "# bvps_top_pca = compute_ranking(snr_peaks_pca,bvps_pca, 0.30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO_oyyXBAl15"
      },
      "source": [
        "# bvps_final = []\n",
        "# for w in zip(bvps_top, bvps_top_pca, bvps_top_pos):\n",
        "#   bvps_final.append(np.concatenate([w[0], w[1], w[2]], axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q6ynDAX94sV"
      },
      "source": [
        "# bpmES_top = BVP_to_BPM(bvps_final, fps)\n",
        "# median_bpmES_top = multi_est_BPM_median(bpmES_top)\n",
        "# from pyVHR.utils.errors import getErrors, printErrors, displayErrors\n",
        "# RMSE, MAE, MAX, PCC = getErrors(np.expand_dims(median_bpmES_top, axis=0), bpmGT, timesES, timesGT)\n",
        "# printErrors(RMSE, MAE, MAX, PCC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEOKsQKR-W5B"
      },
      "source": [
        "# visualize_BPMs([[median_bpmES, timesES, \"medianES\"], [median_bpmES_top, timesES, \"top_patches\"], [hol_bpmES, hol_timesES, \"holistic\"], [bpmGT, timesGT, \"GT\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW-BzjYk-One"
      },
      "source": [
        "# visualize_BVPs_PSD(bvps_final, 30, fps)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}